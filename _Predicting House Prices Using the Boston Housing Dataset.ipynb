{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3adc60-3db6-4fac-8638-4c17688b21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "106bf294-6431-478c-b36e-52f7c0c09c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90    NaN  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99    NaN  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv(\"HousingData.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a486ecd2-31f5-439c-9286-15fb683c5501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "def load_boston_data():\n",
    "    data = fetch_california_housing()\n",
    "    df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "    df['MEDV'] = data.target  # still calling it MEDV for consistency\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b98686-13c4-4a03-a982-40a46255f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinearRegression:\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_b = np.c_[np.ones(X.shape[0]), X]\n",
    "        XTX = X_b.T @ X_b\n",
    "        XTy = X_b.T @ y\n",
    "        self.weights = np.linalg.solve(XTX, XTy)\n",
    "        self.bias = self.weights[0]\n",
    "        self.weights = self.weights[1:]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "911cbbf2-e95e-4d53-a546-49a0e33de5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom Decision Tree\n",
    "class CustomDecisionTree:\n",
    "    def __init__(self, max_depth=3, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "    \n",
    "    def fit(self, X, y, depth=0):\n",
    "        if depth >= self.max_depth or len(y) < self.min_samples_split:\n",
    "            return {'value': np.mean(y)}\n",
    "        \n",
    "        best_split = self.find_best_split(X, y)\n",
    "        if not best_split:\n",
    "            return {'value': np.mean(y)}\n",
    "        \n",
    "        feature, threshold = best_split['feature'], best_split['threshold']\n",
    "        left_idx = X[:, feature] <= threshold\n",
    "        right_idx = ~left_idx\n",
    "        \n",
    "        if sum(left_idx) < self.min_samples_split or sum(right_idx) < self.min_samples_split:\n",
    "            return {'value': np.mean(y)}\n",
    "        \n",
    "        return {\n",
    "            'feature': feature,\n",
    "            'threshold': threshold,\n",
    "            'left': self.fit(X[left_idx], y[left_idx], depth + 1),\n",
    "            'right': self.fit(X[right_idx], y[right_idx], depth + 1)\n",
    "        }\n",
    "    \n",
    "    def find_best_split(self, X, y):\n",
    "        best_mse = float('inf')\n",
    "        best_split = None\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        for feature in range(n_features):\n",
    "            thresholds = np.percentile(X[:, feature], np.linspace(10, 90, 10))\n",
    "            for threshold in thresholds:\n",
    "                left_idx = X[:, feature] <= threshold\n",
    "                right_idx = ~left_idx\n",
    "                if sum(left_idx) < self.min_samples_split or sum(right_idx) < self.min_samples_split:\n",
    "                    continue\n",
    "                y_left, y_right = y[left_idx], y[right_idx]\n",
    "                mse = (len(y_left) * np.var(y_left) + len(y_right) * np.var(y_right)) / len(y)\n",
    "                if mse < best_mse:\n",
    "                    best_mse = mse\n",
    "                    best_split = {'feature': feature, 'threshold': threshold}\n",
    "        \n",
    "        return best_split\n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.tree = self.tree or {'value': 0}  # Ensure tree exists\n",
    "        return np.array([self.predict_one(x, self.tree) for x in X])\n",
    "    \n",
    "    def predict_one(self, x, node):\n",
    "        if 'value' in node:\n",
    "            return node['value']\n",
    "        if x[node['feature']] <= node['threshold']:\n",
    "            return self.predict_one(x, node['left'])\n",
    "        return self.predict_one(x, node['right'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce68f867-64f3-4063-9e8f-84c83af22226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Random Forest\n",
    "class CustomRandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=3, min_samples_split=2):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        for _ in range(self.n_trees):\n",
    "            idx = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            X_sample, y_sample = X[idx], y[idx]\n",
    "            tree = CustomDecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            tree.tree = tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.mean(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "508561dd-9663-4efa-8ebf-61f2dca95dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomXGBoost:\n",
    "    def __init__(self, n_estimators=10, max_depth=3, learning_rate=0.1, min_samples_split=2):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.trees = []\n",
    "        self.initial_prediction = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.initial_prediction = np.mean(y)\n",
    "        predictions = np.full_like(y, self.initial_prediction)\n",
    "        \n",
    "        for _ in range(self.n_estimators):\n",
    "            residuals = y - predictions\n",
    "            tree = CustomDecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            tree.tree = tree.fit(X, residuals)\n",
    "            self.trees.append(tree)\n",
    "            tree_preds = tree.predict(X)\n",
    "            predictions += self.learning_rate * tree_preds\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.full(X.shape[0], self.initial_prediction)\n",
    "        for tree in self.trees:\n",
    "            predictions += self.learning_rate * tree.predict(X)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f02be873-f8a3-4544-be34-d1399f237503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    return r2_score(y_true, y_pred)\n",
    "\n",
    "# Feature Importance\n",
    "def get_feature_importance(model, X, feature_names):\n",
    "    if isinstance(model, (CustomRandomForest, CustomXGBoost)):\n",
    "        importance = np.zeros(X.shape[1])\n",
    "        trees = model.trees\n",
    "        n_trees = len(trees)\n",
    "        for tree in trees:\n",
    "            importance += compute_tree_importance(tree.tree, X.shape[1])\n",
    "        importance /= n_trees\n",
    "        return pd.Series(importance, index=feature_names)\n",
    "    return None\n",
    "\n",
    "def compute_tree_importance(node, n_features):\n",
    "    importance = np.zeros(n_features)\n",
    "    if 'value' in node:\n",
    "        return importance\n",
    "    feature = node['feature']\n",
    "    importance[feature] += 1  # Count splits\n",
    "    importance += compute_tree_importance(node['left'], n_features)\n",
    "    importance += compute_tree_importance(node['right'], n_features)\n",
    "    return importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c327f60-6334-4612-8cde-16e9d5c8a689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (20640, 9)\n",
      "\n",
      "First 5 Rows:\n",
      "    MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude   MEDV  \n",
      "0    -122.23  4.526  \n",
      "1    -122.22  3.585  \n",
      "2    -122.24  3.521  \n",
      "3    -122.25  3.413  \n",
      "4    -122.25  3.422  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 61\u001b[0m\n\u001b[0;32m     58\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 61\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[17], line 16\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m X \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining Set Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Set Shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load data\n",
    "    df = load_boston_data()\n",
    "    print(\"Dataset Shape:\", df.shape)\n",
    "    print(\"\\nFirst 5 Rows:\\n\", df.head())\n",
    "    \n",
    "    # Preprocessing\n",
    "    X = df.drop(columns=['MEDV']).values\n",
    "    y = df['MEDV'].values\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(\"\\nTraining Set Shape:\", X_train.shape)\n",
    "    print(\"Test Set Shape:\", X_test.shape)\n",
    "    \n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Linear Regression': CustomLinearRegression(),\n",
    "        'Random Forest': CustomRandomForest(n_trees=10, max_depth=3, min_samples_split=2),\n",
    "        'XGBoost': CustomXGBoost(n_estimators=10, max_depth=3, learning_rate=0.1, min_samples_split=2)\n",
    "    }\n",
    "    # Train and evaluate\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        results[name] = {\n",
    "            'RMSE': rmse(y_test, y_pred),\n",
    "            'R2': r2(y_test, y_pred)\n",
    "        }\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n=== Model Performance ===\")\n",
    "    for name, metrics in results.items():\n",
    "        print(f\"{name}:\")\n",
    "        print(f\"  RMSE: {metrics['RMSE']:.4f}\")\n",
    "        print(f\"  R2: {metrics['R2']:.4f}\")\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    feature_names = df.drop(columns=['MEDV']).columns\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    for i, name in enumerate(['Random Forest', 'XGBoost'], 1):\n",
    "        importance = get_feature_importance(models[name], X, feature_names)\n",
    "        if importance is not None:\n",
    "            plt.subplot(1, 2, i)\n",
    "            sns.barplot(x=importance.values, y=importance.index)\n",
    "            plt.title(f'{name} Feature Importance')\n",
    "            plt.xlabel('Importance (Split Count)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('house_price_prediction/feature_importance.png')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d5fc8-931e-4857-844e-494e92bf7278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
